import importlib
import sys
import os
import traceback
import argparse
import urllib
import urllib3
import string

allParsers = ['hamburg', 'eppelheim',
              'heidelberg', 'mannheim', 'stuttgart', 'ulm']

repoPath = os.path.dirname(__file__)
filenameTemplate = "{base}{{metaOrFeed}}/{parserName}_{{mensaReference}}.xml"
baseUrl = "https://cvzi.github.io/mensahd/"
baseRepo = "https://github.com/cvzi/mensahd/"
basePath = "docs/"


log_file = None
greenOk = "Ok" if "idlelib" in sys.modules else "\033[1;32mOk\033[0m"
redError = "Error" if "idlelib" in sys.modules else "\033[1;31m‚ö†Ô∏è Error\033[0m"


def log(*objects, sep=' ', end='\n', file=sys.stdout, flush=False):
    print(*objects, sep=sep, end=end, file=file, flush=flush)
    if log_file and not log_file.closed:
        print(*objects, sep=sep, end=end, file=log_file, flush=flush)


def generateIndexHtml(baseUrl, basePath, errors=None):
    files = []

    for r, _, f in os.walk(os.path.join(repoPath, basePath)):
        p = baseUrl + r[len(os.path.join(repoPath, basePath)):]
        if p[-1] != '/':
            p += '/'
        for file in f:
            if file.endswith(('.xml', '.json')):
                files.append(f"{p}{file}")

    with open(os.path.join(repoPath, 'html/index.html'), 'r', encoding='utf8') as f:
        template = string.Template(f.read())

    def sortKey(s):
        parts = s[len(baseUrl):].split('/')
        s = parts[-1].upper() + (parts[-2] if len(parts) > 1 else "")
        return s

    content = []
    first = True

    for file in sorted(files, key=sortKey):
        if file.endswith('.json'):
            if not first:
                content.append('</ul>')
            first = False

            content.append(
                f'<li><h3 id="{file[len(baseUrl):-5]}"><a href="{file}">üêè {file[len(baseUrl):]}</a></h3>')
            content.append('<ul style="list-style-type:none">')
        else:
            icon = 'üà∫' if '/meta/' in file else 'üç±'
            content.append(
                f'  <li><a href="{file}">{icon} {file[len(baseUrl):]}</a></li>')
    content.append('</ul>')
    content.append('</li>')
    content = '<ol style="list-style-type:none">\n' + \
        '\n'.join(content) + '\n</ol>'

    content = f'\n{content}\n'

    status = f'<h3><a href="{baseRepo}actions/">üóø Parser status</a></h3>'
    if errors:
        status += '\n<pre>' + '\n'.join(errors) + '</pre>'

    with open(os.path.join(repoPath, basePath, 'index.html'), 'w', encoding='utf8') as f:
        f.write(template.substitute(content=content, status=status))


def updateFeeds(force=None,
                updateJson=True,
                updateMeta=True,
                updateFeed=True,
                updateToday=False,
                updateIndex=True,
                selectedParser='',
                selectedMensa='',
                baseUrl=baseUrl,
                basePath=basePath):

    errors = []

    for parserName in allParsers:
        if not updateJson and not updateMeta and not updateFeed and not updateToday:
            continue
        if selectedParser and parserName != selectedParser:
            continue
        log(f"üó≥Ô∏è {parserName}")
        try:
            module = importlib.import_module(parserName)
            parser = module.getParser(filenameTemplate.format(
                base=baseUrl, parserName=parserName))

            if updateJson:
                filename = os.path.join(basePath, f'{parserName}.json')
                log(f" - üêè {filename}", end="", flush=True)
                os.makedirs(os.path.dirname(filename), exist_ok=True)
                content = parser.json()
                with open(os.path.join(repoPath, filename), 'w', encoding='utf8') as f:
                    f.write(content)
                log(f"  {greenOk}")

            canteenCounter = 0
            for mensaReference in parser.canteens:
                if selectedMensa and selectedMensa != mensaReference:
                    continue
                log(f"  - üè´ {mensaReference}")
                try:
                    if updateMeta:
                        filename = filenameTemplate.format(base=basePath, parserName=parserName).format(
                            metaOrFeed='meta', mensaReference=mensaReference)
                        log(f"    - üà∫ {filename}", end="", flush=True)
                        os.makedirs(os.path.dirname(filename), exist_ok=True)
                        content = parser.meta(mensaReference)
                        with open(os.path.join(repoPath, filename), 'w', encoding='utf8') as f:
                            f.write(content)
                        log(f"  {greenOk}")
                    if updateFeed or updateToday:
                        if updateToday:
                            feedMethods = [feedMethod for feedMethod in [
                                "feed_today"] if hasattr(parser, feedMethod)]
                            if not feedMethods and not updateMeta:
                                log("\033[F\033[K", end="")
                        else:
                            feedMethods = [feedMethod for feedMethod in [
                                "feed", "feed_today", "feed_all", "feed_full"] if hasattr(parser, feedMethod)]
                        for feedMethod in feedMethods:
                            fileTitle = "today" if feedMethod == "feed_today" else "feed"
                            filename = filenameTemplate.format(base=basePath, parserName=parserName).format(
                                metaOrFeed=fileTitle, mensaReference=mensaReference)
                            log(f"    - üç± {filename}", end="", flush=True)
                            os.makedirs(os.path.dirname(
                                filename), exist_ok=True)
                            content = getattr(parser, feedMethod)(
                                mensaReference)
                            if type(content) is bytes:
                                with open(os.path.join(repoPath, filename), 'wb') as f:
                                    f.write(content)
                            else:
                                with open(os.path.join(repoPath, filename), 'w', encoding='utf8') as f:
                                    f.write(content)
                            log(f"  {greenOk}")
                except KeyboardInterrupt as e:
                    raise e
                except (IOError, ConnectionError, urllib.error.URLError, urllib3.exceptions.HTTPError) as e:
                    if canteenCounter == 0:
                        # Assumption: this errors affects the whole parser, skip the whole parser
                        raise e
                    else:
                        log(f"  {redError}")
                        traceback.print_exc()
                except BaseException:
                    log(f"  {redError}")
                    traceback.print_exc()
                    errors.append(f"{parserName}/{mensaReference}:")
                    errors.append(traceback.format_exc())
                canteenCounter += 1

        except KeyboardInterrupt:
            log(" [Control-C]")
            return 130
        except BaseException:
            log(f"  {redError}")
            errors.append(f"{parserName}:")
            errors.append(traceback.format_exc())
            traceback.print_exc()

    if updateIndex:
        log(" - üìÑ index.html", end="", flush=True)
        generateIndexHtml(baseUrl=baseUrl, basePath=basePath, errors=errors)
        log(f"  {greenOk}")

    return min(0, len(errors))


def startFromTerminal(exitAfterwards=True):
    # Arguments
    parser = argparse.ArgumentParser(
        description='Update github pages')
    parser.add_argument(
        '-force',
        dest='force',
        action='store_const',
        const=True,
        default=False,
        help='Force update')
    parser.add_argument(
        '-meta',
        dest='updateMeta',
        action='store_const',
        const=True,
        default=False,
        help='Update meta xml')
    parser.add_argument(
        '-feed',
        dest='updateFeed',
        action='store_const',
        const=True,
        default=False,
        help='Update all feed xml')
    parser.add_argument(
        '-today',
        dest='updateToday',
        action='store_const',
        const=True,
        default=False,
        help='Update today feed xml')
    parser.add_argument(
        '-json',
        dest='updateJson',
        action='store_const',
        const=True,
        default=False,
        help='Update json')
    parser.add_argument(
        '-index',
        dest='updateIndex',
        action='store_const',
        const=True,
        default=False,
        help='Update index.html')
    parser.add_argument(
        '-parser',
        dest='selectedParser',
        default='',
        help='Parser name')
    parser.add_argument(
        '-canteen',
        dest='selectedMensa',
        default='',
        help='Mensa reference')
    parser.add_argument(
        '-url',
        dest='baseUrl',
        default=baseUrl,
        help='Base URL')
    parser.add_argument(
        '-out',
        dest='basePath',
        default=basePath,
        help='Output directory')

    args = parser.parse_args()

    exitCode = updateFeeds(**vars(args))

    if exitAfterwards:
        sys.exit(exitCode)
    return exitCode


if __name__ == "__main__":
    startFromTerminal()
